[Ch7. ML의 활용팁]

Learning rate
	- overshooting: learning rate 값을 너무 큰 값으로 잡으면 생기는 현상
	- learning rate 값이 너무 작으면 시간이 너무 오래걸림
	
	- 답은 없다
	- 0.01로 시작해보고 cost 값을 보며 재할당


Data(X) preprocessing (for gradient descent)
	x1, x2의 차이가 너무 크면 한 쪽으로 길죽한 모양의 그래프가 생김
	=> normalized data로 preprocessing
	
	식
		x'j = (xj - mj) / oj
	
	파이썬에서
		X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()


Overfitting
	너무 학습데이터에 딱 맞는 모델이 생성되어 테스트데이터에는 잘 맞지 않는 현상
	=> training data가 많으면 많을수록 좋음
	=> feature의 수를 줄이는 방법
	=> Regularization(일반화) 시키는 방법

	Regularization
		not have too big numbers in the weight
		L = [~~~~~] + ㅅ[총합]W^2
				* ㅅ = regularization strength
				l2reg = 0.001 * tf.reduce_sum(tf.squre(W))


ML Model의 Evaluation
	training set을 나눈다
	30%정도 test set으로 빼고 70%로 training한다
	
	70%의 training set을 다시 2개로 나눈다
	[Training] [Validation] (마치 실전 모의고사)
			learning_rate, regularization strength의 값을 정해보는 data

	** [Training set] [Validation set] [Test set]


Online learning
	새로운 data set이 들어오면 존재하는 model에 새로운 data set만 학습시킴

Accuracy
	95~99%








